<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>论文笔记 - ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</title>
    <link href="/2024/11/26/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices/"/>
    <url>/2024/11/26/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices/</url>
    
    <content type="html"><![CDATA[<h2 id="1-Information"><a href="#1-Information" class="headerlink" title="1. Information"></a>1. Information</h2><p><strong>Title</strong>: ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices<br><strong>Link</strong>: <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.pdf">ShuffleNet Paper</a><br><strong>Source</strong>: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br><strong>Date</strong>: 2018</p><h2 id="2-Summary"><a href="#2-Summary" class="headerlink" title="2. Summary"></a>2. Summary</h2><p>本文提出了 ShuffleNet，一种针对移动设备的高效卷积神经网络。核心创新是<strong>通道混洗（channel shuffle）</strong>操作，它在不牺牲准确性的情况下，减少了计算量和模型大小。文章提出了两项关键技术：</p><ol><li><strong>逐点组卷积（pointwise group convolution）</strong>：通过将 1x1 卷积操作分组，减少了参数和计算量。</li><li><strong>通道混洗（channel shuffle）</strong>：这一操作在组卷积后重排特征通道，提升了网络的表示能力。</li></ol><h2 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h2><p>由于移动设备面临资源受限的挑战，如何设计高效的神经网络模型变得尤为重要。传统的 CNN 架构计算开销大，限制了它们在移动平台上的应用。</p><h2 id="4-Research-Objective"><a href="#4-Research-Objective" class="headerlink" title="4. Research Objective"></a>4. Research Objective</h2><p>本研究的主要目标是设计一种计算高效且能够保持高准确率的CNN架构，特别是针对移动设备的部署。具体来说，研究目标是：</p><ol><li>在保证高准确度的同时，减少模型的计算开销（FLOPs）。</li><li>确保模型在内存使用和模型大小方面高效，以便在实际移动设备中使用。</li></ol><h2 id="5-Method"><a href="#5-Method" class="headerlink" title="5. Method"></a>5. Method</h2><h4 id="Channel-Shuffle-for-Group-Convolutions"><a href="#Channel-Shuffle-for-Group-Convolutions" class="headerlink" title="Channel Shuffle for Group Convolutions"></a>Channel Shuffle for Group Convolutions</h4><p>现有的模型在使用组卷积时，往往忽视了 1×1 卷积（逐点卷积），导致该操作占据了大量计算开销。本文提出了在 1×1 卷积中使用分组卷积，以减少计算量。</p><p>然而，分组卷积会使得每个通道的输出仅来自部分输入通道。为了解决这一问题，作者提出了通道洗牌技术，如下图（b）和（c）所示。假设某个卷积层被划分为 g 组，每组的输出特征维度为 n，首先将其堆叠成形状为（g, n）的张量，再对其进行转置操作，最后将其拉平，完成通道之间的信息洗牌。</p><p align="center">  <img src="1.png" style="zoom:67%;" /></p><h4 id="ShuffleNet-Unit"><a href="#ShuffleNet-Unit" class="headerlink" title="ShuffleNet Unit"></a>ShuffleNet Unit</h4><p>基于通道混洗操作，本文提出了 ShuffleNet 单元，如下图所示。</p><p align="center">  <img src="2.png" style="zoom:67%;" /></p><p>其中，(a) 为 ResNet 中的基本块，本文将其中的 1×1 卷积替换为分组卷积，并在第一个分组卷积之后加入了通道混洗操作。</p><p>在需要缩减图像尺寸的情况下，如图(c)所示，在直接连接路径上使用 3×3 的平均池化操作，并将原本在 ResNet 中的相加操作替换为通道串联操作，从而增加通道维度。</p><h2 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h2><p>作者通过以下方式评估了ShuffleNet的性能：</p><ul><li>在 ImageNet 数据集上的<strong>Top-1和Top-5准确率</strong>。</li><li><strong>FLOPs</strong>（浮点运算）用于衡量计算效率。</li><li><strong>模型大小</strong>和<strong>内存使用</strong>，评估其在移动设备上的可行性。</li></ul><p>ShuffleNet 在准确率和效率上超越了其他高效 CNN 架构（如 MobileNet），实现了性能与计算开销的良好平衡。</p><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>ShuffleNet 通过创新地结合组卷积和通道混洗操作，设计出了极高效的卷积神经网络，特别适合移动设备使用。实验结果表明，ShuffleNet 在计算开销大幅降低的同时，依然能够保持良好的准确率。该方法在实时移动应用中具有很大的潜力，尤其是在速度和内存效率至关重要的场景下。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>训练加速</tag>
      
      <tag>算法优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文笔记 - Densely Connected Convolutional Networks</title>
    <link href="/2024/11/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Densely-Connected-Convolutional-Networks/"/>
    <url>/2024/11/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Densely-Connected-Convolutional-Networks/</url>
    
    <content type="html"><![CDATA[<h2 id="1-Information"><a href="#1-Information" class="headerlink" title="1. Information"></a>1. Information</h2><p><strong>Title</strong>: Densely Connected Convolutional Networks<br><strong>Link</strong>: <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf">DenseNet Paper</a><br><strong>Source</strong>: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br><strong>Date</strong>: 2017</p><h2 id="2-Summary"><a href="#2-Summary" class="headerlink" title="2. Summary"></a>2. Summary</h2><p>本文提出了 DenseNet，一种新的深度学习架构，在该架构中，每一层都接收来自所有前面层的输入，形成密集的连接。与传统的卷积神经网络只传递前一层的信息不同，DenseNet 为每一层创建了来自所有前一层的直接连接。该设计显著改善了梯度流动并促进了特征重用，从而实现了更高效的网络，并且参数更少。</p><h2 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h2><p>DenseNet 基于传统 CNN 架构，解决了梯度消失和参数冗余等关键问题。密集连接的概念受到残差网络（ResNet）成功的启发，但DenseNet 通过完全连接每一层的方式进行了更为激进的改进。这项研究在深度学习领域具有重要意义，特别是在提高图像分类、物体检测等任务的网络效率和性能方面。</p><h2 id="4-Research-Objective"><a href="#4-Research-Objective" class="headerlink" title="4. Research Objective"></a>4. Research Objective</h2><p>本研究的主要目标是提出并验证 DenseNet 作为一种更高效的深度学习架构，旨在缓解传统 CNN 中梯度消失和特征冗余的问题。研究旨在展示 DenseNet 在准确性和参数效率方面相较于传统架构的优势。</p><h2 id="5-Method"><a href="#5-Method" class="headerlink" title="5. Method"></a>5. Method</h2><p>DenseNet 架构由多个层块组成，层块内的每一层都与之前的所有层进行连接，如下图所示：</p><p align="center">  <img src="1.png" style="zoom:80%;" /></p><p>在每个层块内，特征图的大小保持不变，而层块之间通过过渡层实现特征图的下采样。</p><p>DenseNet 的显著特点之一是每一层的输出特征图维度非常窄，输出通道数被称为增长率 $k$。虽然每层的输出维度固定为 $k$，但输入特征图的维度随着网络深度的增加而逐步增多。为提升计算效率，DenseNet 在每个 3×3 卷积之前引入 1×1 卷积作为瓶颈层，以减少输入特征图的数量。</p><p>此外，通过在过渡层引入压缩因子 $\theta$，进一步提升了模型的紧凑性，使 DenseNet 更高效地利用计算资源。</p><h2 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h2><p>作者使用标准数据集（如 CIFAR-10、CIFAR-100 和 ImageNet）对 DenseNet 进行了评估，结果表明 DenseNet 在准确性和参数数量方面都显著优于传统 CNN，显示出更强的泛化能力。通过广泛的消融研究，分析了密集连接对性能的影响。</p><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>DenseNet 通过引入密集层连接，提供了一种有效的解决方案，提升了深度神经网络的效率。这一创新使得网络训练更快、准确性更高，同时参数更少。研究表明，DenseNet 可以成为处理大数据集和深度学习任务中的一个有价值的架构。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>训练加速</tag>
      
      <tag>算法优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文笔记 - Aggregated Residual Transformations for Deep Neural Networks</title>
    <link href="/2024/11/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/"/>
    <url>/2024/11/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/</url>
    
    <content type="html"><![CDATA[<h2 id="1-Information"><a href="#1-Information" class="headerlink" title="1. Information"></a>1. Information</h2><p><strong>Title</strong>: Aggregated Residual Transformations for Deep Neural Networks<br><strong>Link</strong>: <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.pdf">ResNeXt Paper</a><br><strong>Source</strong>: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br><strong>Date</strong>: 2017</p><h2 id="2-Summary"><a href="#2-Summary" class="headerlink" title="2. Summary"></a>2. Summary</h2><p>本文提出了 <strong>ResNeXt</strong>，一种改进的残差网络架构，通过引入<strong>聚合变换（Aggregated Transformations）</strong>增强模型表达能力。核心创新是引入了<strong>基数（Cardinality）</strong>的概念，即网络中路径的数量。ResNeXt 在显著提升性能的同时，保持了较低的计算复杂度，并在 ImageNet、CIFAR-10 和 CIFAR-100 等基准数据集上达到了最先进的性能。</p><h2 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h2><p>深度神经网络（如 ResNet）通过堆叠多个层及跳跃连接在视觉任务中取得了显著成功。然而，仅增加网络的深度或宽度带来的性能提升逐渐减小，同时计算成本迅速增加。受 Inception 等多分支架构的启发，ResNeXt 提出了一个更简单且更高效的聚合策略，通过<strong>并行路径的聚合变换</strong>在性能与效率之间取得了平衡。</p><h2 id="4-Research-Objective"><a href="#4-Research-Objective" class="headerlink" title="4. Research Objective"></a>4. Research Objective</h2><p>本文的研究目标是通过引入<strong>基数（Cardinality）</strong>提升深度网络的表达能力，同时保持计算效率。具体目标包括：</p><ol><li>提供一种更简洁的多分支架构设计方法；</li><li>验证 ResNeXt 的可扩展性及其在不同任务中的通用性；</li><li>在不显著增加计算成本的情况下实现最先进的性能。</li></ol><h2 id="5-Method"><a href="#5-Method" class="headerlink" title="5. Method"></a>5. Method</h2><ul><li><p><strong>关键创新</strong>：</p><p>引入了基数的概念，下图左边为原始的 ResNet 架构；右边为增加了基数的改进版本，每个残差模块包含多条路径，路径数由基数控制，所有路径的输出聚合后再与输入进行残差连接。</p><p align="center">  <img src="1.png" style="zoom:60%;" /></p><p>引入<strong>分组卷积（Grouped Convolution）</strong>以实现多路径聚合变换，下图 (a) 和 (b) 表示相同，图 (c) 使用了分组卷积，降低了计算复杂度。</p><ul><li><p>分组卷积将输入通道划分为多个组，每组独立进行卷积操作，降低了计算复杂度。</p></li><li><p>各组的输出通过聚合操作合并，实现模块化和可扩展性。</p></li></ul><p align="center">  <img src="2.png" style="zoom:60%;" /></p></li><li><p><strong>架构设计</strong>：</p><ul><li>ResNeXt 的残差模块在 ResNet 的基础上，将瓶颈层的单一卷积替换为分组卷积。</li><li>基数（Cardinality）表示分组的数量，是控制并行路径数量的超参数。</li></ul></li><li><p><strong>与其他架构的比较</strong>：</p><ul><li>ResNeXt 在深度（ResNet）和宽度（VGG）之外，提出了新的扩展维度——基数，通过增加基数实现性能提升，同时保持计算效率。</li></ul></li></ul><h2 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h2><ul><li><p><strong>数据集</strong>：ImageNet、CIFAR-10 和 CIFAR-100。</p></li><li><p><strong>评估指标</strong>：分类任务的 Top-1 和 Top-5 准确率。</p></li><li><p><strong>实验结果</strong>：</p><ul><li><p>在相同的深度和宽度下，ResNeXt 比 ResNet 表现更优，准确率更高。</p></li><li><p>实验证明，增加基数相比单纯增加深度或宽度更能显著提升网络性能。</p></li></ul></li><li><p><strong>消融实验</strong>：验证了分组卷积的有效性，以及基数对模型性能的影响。</p></li></ul><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>ResNeXt 提供了一种通过聚合变换改进神经网络性能的简单方法。通过增加基数，ResNeXt 实现了更高的准确率，同时保持了较低的计算成本。研究表明，基数是扩展深度网络性能的重要维度，提供了增加深度或宽度之外的一种灵活替代方案。</p><h2 id="8-Notes"><a href="#8-Notes" class="headerlink" title="8. Notes"></a>8. Notes</h2><ol><li><strong>什么是分组卷积</strong>？</li></ol><blockquote><p>分组卷积的核心思想是将卷积操作的输入通道和输出通道分组，然后在每组上独立执行卷积操作，最后将各组的输出拼接在一起。</p><ul><li><strong>传统卷积</strong>：<ul><li>输入特征图和卷积核的所有通道之间会进行完全连接的卷积操作。</li><li>假设输入的通道数为 $C_{\text {in }}$，输出通道数为 $C_{\text {out }}$，卷积核大小为 $k \times k$，传统卷积需要的参数量为：</li></ul></li></ul><p>$$<br>C_{\text {in }} \times C_{\text {out }} \times k \times k<br>$$</p><ul><li><strong>分组卷积</strong>：<ul><li>将输入通道划分为 $g$ 组（每组有 $C_{\text {in }}$ &#x2F; $g$ 个通道），输出通道也划分为 $g$ 组（每组有 $C_{\text {out }}$ &#x2F; $g$ 个通道）。</li><li>每组卷积仅计算输入通道的一部分，从而减少了计算量。</li><li>参数量为：</li></ul></li></ul><p>$$<br>\left(C_{\text {in }} &#x2F; g\right) \times\left(C_{\text {out }} &#x2F; g\right) \times k \times k \times g&#x3D;\frac{C_{\text {in }} \times C_{\text {out }} \times k \times k}{g}<br>$$</p></blockquote><ol start="2"><li><strong>ResNeXt 与 Inception-ResNet 的对比</strong></li></ol><blockquote><table><thead><tr><th><strong>特性</strong></th><th><strong>ResNeXt</strong></th><th><strong>Inception-ResNet</strong></th></tr></thead><tbody><tr><td><strong>路径结构</strong></td><td>等价路径（分组卷积）</td><td>非等价路径（不同卷积核和池化操作）</td></tr><tr><td><strong>模块复杂度</strong></td><td>简单、模块化</td><td>复杂、需手动调优</td></tr><tr><td><strong>计算复杂度</strong></td><td>更低，参数更少</td><td>较高，参数较多</td></tr><tr><td><strong>特征表达能力</strong></td><td>高效，通过增加基数捕获更多特征</td><td>优秀，能捕获多尺度特征</td></tr><tr><td><strong>扩展性和通用性</strong></td><td>高，易于在深层网络中扩展</td><td>中等，适合特定任务（如多尺度特征处理）</td></tr><tr><td><strong>适用场景</strong></td><td>大规模训练、深层分类网络</td><td>需要多尺度特征融合的任务（如检测、分割）</td></tr></tbody></table></blockquote>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>训练加速</tag>
      
      <tag>算法优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文笔记 - Rethinking the Inception Architecture for Computer Vision</title>
    <link href="/2024/11/22/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Rethinking-the-Inception-Architecture-for-Computer-Vision/"/>
    <url>/2024/11/22/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Rethinking-the-Inception-Architecture-for-Computer-Vision/</url>
    
    <content type="html"><![CDATA[<h2 id="1-Information"><a href="#1-Information" class="headerlink" title="1. Information"></a>1. Information</h2><p><strong>Title</strong>: Rethinking the Inception Architecture for Computer Vision<br><strong>Link</strong>: <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf">Inception V3 Paper</a><br><strong>Source</strong>: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br><strong>Date</strong>: 2016</p><h2 id="2-Summary"><a href="#2-Summary" class="headerlink" title="2. Summary"></a>2. Summary</h2><p>本文重新审视了 Inception V1 架构并提出了一系列改进，提升了其效率和性能，从而推出了 Inception V3 模型。这些改进包括优化计算成本、减少参数数量，以及在保持高效表示的同时增加网络的深度和宽度。在 ImageNet 数据集上，这些模型在减少计算预算的同时实现了最先进的性能。</p><h2 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h2><p>Inception 网络是一类在每层内通过多尺度特征提取实现计算效率与性能平衡的架构。最初的 GoogLeNet（Inception V1） 引入了模块化设计，但也带来了参数数量增多和计算开销增加的问题。本研究在 Inception V1 的成功基础上，提出了解决这些局限性的方法，并进一步提升了视觉任务中的准确率和效率。</p><h2 id="4-Research-Objective"><a href="#4-Research-Objective" class="headerlink" title="4. Research Objective"></a>4. Research Objective</h2><ol><li>减少网络计算成本和参数数量。</li><li>平衡网络深度与宽度以实现最优性能。</li><li>探索新的技术，例如卷积因式分解和辅助损失层。</li></ol><h2 id="5-Method"><a href="#5-Method" class="headerlink" title="5. Method"></a>5. Method</h2><h3 id="卷积因式分解"><a href="#卷积因式分解" class="headerlink" title="卷积因式分解"></a><strong>卷积因式分解</strong></h3><p>用多个较小的卷积（如 3×3 或 1×1 ）替代较大的卷积（如 5×5 ），以降低计算成本。</p><p align="center">  <img src="1.png" style="zoom:80%;" /></p><p>将较大的卷积核（5×5）分解为两个小卷积核（如 1×5 和 5×1 ），降低参数量和计算复杂度。</p><p align="center">  <img src="2.png" style="zoom:80%;" /></p><h3 id="高效网格尺寸缩减"><a href="#高效网格尺寸缩减" class="headerlink" title="高效网格尺寸缩减"></a><strong>高效网格尺寸缩减</strong></h3><p>如图 9 所示，左侧方法虽然降低了特征图尺寸，但容易引发表征瓶颈；右侧方法虽能缓解表征瓶颈，却带来了较高的计算开销。而图 10 中的方法在避免表征瓶颈的基础上，成功实现了计算开销的显著降低。</p><p align="center">  <img src="3.png" style="zoom:80%;" /></p><h3 id="辅助分类器"><a href="#辅助分类器" class="headerlink" title="辅助分类器"></a><strong>辅助分类器</strong></h3><p>早期的 GoogLeNet 使用辅助分类器主要是为了缓解梯度消失问题。但 Inception V3 中研究了它的<strong>正则化效果</strong>，发现即使在没有梯度消失问题的情况下，辅助分类器仍然能提高网络的泛化能力。</p><h3 id="Label-Smoothing技术"><a href="#Label-Smoothing技术" class="headerlink" title="Label Smoothing技术"></a><strong>Label Smoothing技术</strong></h3><p>在传统的分类任务中，目标函数通常使用交叉熵损失（Cross-Entropy Loss），其中真实类别的标签被表示为 <strong>one-hot 编码</strong>（即目标类别为 1，其他类别为 0）。这种方式在训练时可能导致模型对目标类别的预测概率非常接近 1，而对其他类别接近 0，从而导致过拟合问题。Label Smoothing 是一种通过调整目标分布的方法，避免模型过度自信。它将原始的 one-hot 分布替换为一个“平滑”的分布，即目标类别的标签值被减小，而非目标类别的标签值被稍微增加：<br>$$<br>q^{\prime}(k)&#x3D; \begin{cases}1-\epsilon+\frac{\epsilon}{K}, &amp; \text { if } k&#x3D;y \ \frac{\epsilon}{K}, &amp; \text { if } k \neq y\end{cases}<br>$$</p><ul><li>$q^{\prime}(k)$：经过平滑后的标签分布。</li><li>$\epsilon$：平滑因子，通常是一个较小的正值，例如 0.1。</li><li>$K$：类别总数。</li><li>$y$：真实类别索引。</li></ul><p>这样，目标分布会从严格的 one-hot 变成一个软分布。</p><h2 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h2><p>模型在<strong>ImageNet数据集</strong>上进行评估，这是大规模图像分类的基准。</p><ul><li><strong>评估指标</strong>：Top-1 和 Top-5 分类准确率。</li><li><strong>结果</strong>：Inception V3 在与前代架构相比时显著提升了准确率，同时降低了计算成本。</li><li><strong>实验验证</strong>：提出的技术（如卷积因式分解和批量归一化）对性能提升起到了关键作用。</li></ul><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>本文成功提出了一种改进的 Inception 架构，在计算效率和性能之间实现了平衡。因式分解卷积和改进的训练策略等创新，为设计高效的深度学习架构设立了新的标准。这些发现对构建可扩展、高效的深度学习模型具有广泛意义。</p><h2 id="8-Notes"><a href="#8-Notes" class="headerlink" title="8. Notes"></a>8. Notes</h2><ol><li>虽然 Inception V2 和 Inception V3 都是在同一篇论文 “Rethinking the Inception Architecture for Computer Vision” 中提及，但出于对 Batch Normalization 的强调，很多人习惯性地将 <strong>BN-Inception</strong> 称为 Inception V2。</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>算法优化</tag>
      
      <tag>CV</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文笔记 - Deep Residual Learning for Image Recognition</title>
    <link href="/2024/11/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deep-Residual-Learning-for-Image-Recognition/"/>
    <url>/2024/11/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deep-Residual-Learning-for-Image-Recognition/</url>
    
    <content type="html"><![CDATA[<h2 id="1-Information"><a href="#1-Information" class="headerlink" title="1. Information"></a>1. Information</h2><p><strong>Title</strong>: Deep Residual Learning for Image Recognition<br><strong>Link</strong>: <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">ResNet Paper</a><br><strong>Source</strong>: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br><strong>Date</strong>: 2015</p><h2 id="2-Summary"><a href="#2-Summary" class="headerlink" title="2. Summary"></a>2. Summary</h2><p>本文提出了一种新型的深度学习架构——残差网络（ResNet），它通过引入<strong>残差连接</strong>来解决传统深度神经网络在训练过程中遇到的梯度消失和退化问题。作者通过实验证明，残差网络在多个图像识别任务中，特别是在 ImageNet 图像分类任务上，超越了现有的深度网络架构，达到了更好的效果。该方法可以加速深层网络的训练，并显著提高模型的性能。</p><h2 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h2><p>随着深度学习技术的发展，深度神经网络的应用逐渐取得了许多成功。然而，当网络层数增多时，模型的训练难度也随之增加，通常会遇到梯度消失、过拟合、训练退化等问题。传统的做法是通过增加层数来提升模型的表现，但实际效果往往没有预期那么好，这也成为深度学习研究中的一个瓶颈。因此，如何构建更深且更易训练的网络结构成为研究的热点。</p><h2 id="4-Research-Objective"><a href="#4-Research-Objective" class="headerlink" title="4. Research Objective"></a>4. Research Objective</h2><p>本研究的主要目标是通过引入<strong>残差学习</strong>来改进非常深的网络训练，使其能够更好地进行图像识别任务。</p><h2 id="5-Method"><a href="#5-Method" class="headerlink" title="5. Method"></a>5. Method</h2><ul><li><strong>残差学习</strong>：ResNet 不是直接学习输入和输出之间的映射，而是学习输入与输出之间的残差，即 $\mathcal{F}(x)&#x3D;H(x)-x$，其中 $H(x)$ 是期望的映射。</li></ul><p align="center">  <img src="1.png" style="zoom:67%;" /></p><ul><li><p><strong>网络模块</strong>：该架构由<strong>残差块（Residual Block）</strong>组成，每个残差块中包含一个快捷连接，该连接绕过一个或多个层。</p></li><li><p><strong>深层网络</strong>：通过残差学习，ResNet能够构建任意深度的网络（如 152 层），同时避免性能退化。</p></li><li><p><strong>优化</strong>：快捷连接确保了在反向传播中梯度能够顺利流动，从而更容易训练非常深的网络。</p></li></ul><h2 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h2><ul><li>作者在<strong>ImageNet 2012 分类挑战</strong>中评估了 ResNet 架构，并取得了最先进的结果。ResNet-152 模型的 top-5 错误率为 3.0%，远超之前的模型。</li><li>作者还在 COCO 检测和分割任务中验证了该方法，表现也十分优秀。</li><li>他们将 ResNet 与传统的深度 CNN 模型以及其他网络进行了比较，证明了更深的 ResNet 在准确率上始终优于浅层网络。</li></ul><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><ul><li><strong>残差网络（ResNets）</strong>使得构建非常深的网络成为可能，并且能够避免训练中的性能退化问题，解决了深层神经网络的梯度消失和优化问题。</li><li><strong>残差学习框架</strong>既简单又有效，可以广泛应用于各种任务，除了图像分类，还包括目标检测和图像分割等。</li><li>残差网络的成功表明，更深的网络结构并非一定会导致性能下降，只要能够有效地传递梯度。</li></ul>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>训练加速</tag>
      
      <tag>算法优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文笔记 - Batch Normalization: Accelerating Deep Network Training by  Reducing Internal Covariate Shift</title>
    <link href="/2024/11/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/"/>
    <url>/2024/11/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/</url>
    
    <content type="html"><![CDATA[<h2 id="1-Information"><a href="#1-Information" class="headerlink" title="1. Information"></a>1. Information</h2><p><strong>Title</strong>: Batch Normalization Accelerating Deep Network Training by  Reducing Internal Covariate Shift<br><strong>Link</strong>: <a href="https://asvk.cs.msu.ru/~sveta/%D1%80%D0%B5%D1%84%D0%B5%D1%80%D0%B0%D1%82/batch_normalization.pdf">Batch Normalization Paper</a><br><strong>Source</strong>: International Conference on Machine Learning (ICML)<br><strong>Date</strong>: 2015</p><h2 id="2-Summary"><a href="#2-Summary" class="headerlink" title="2. Summary"></a>2. Summary</h2><p>本文提出了批量归一化（Batch Normalization，BN）技术，通过减少深度神经网络中的内部协变量偏移（internal covariate shift），加速网络训练。内部协变量偏移是指在训练过程中，层输入的分布发生变化。BN 的核心创新是对每一层的输入进行归一化，使其均值为 0，方差为 1，然后进行一个学习的线性变换。BN 加速了收敛速度，允许使用更高的学习率，并且缓解了梯度消失和梯度爆炸的问题。BN 还具有一定的正则化效果，减少了对 Dropout 的需求。</p><h2 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h2><p>深度神经网络在训练时常常面临内部协变量偏移问题，即随着参数的更新，层输入的分布发生变化。这种不稳定性会导致优化过程效率低下，需要精心设计的初始化和学习率调优。之前的解决方法，如预训练和权重初始化，间接解决了这一问题，而 BN 通过直接归一化层输入来解决根本问题。</p><h2 id="4-Research-Objective"><a href="#4-Research-Objective" class="headerlink" title="4. Research Objective"></a>4. Research Objective</h2><ul><li>提出批量归一化方法来减少内部协变量偏移。</li><li>证明BN能够加速训练并提升模型性能。</li><li>评估BN与常用优化方法（如 SGD）兼容性。</li><li>探讨BN的正则化效果及对超参数调节的影响。</li></ul><h2 id="5-Method"><a href="#5-Method" class="headerlink" title="5. Method"></a>5. Method</h2><ul><li><p><strong>归一化</strong>：<br>对每个 mini-batch 中的激活值 $x$，进行归一化：<br>$$<br>\hat{x}&#x3D;\frac{x-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}<br>$$<br>其中，$\mu_B$ 和 $\sigma_B^2$ 分别是 mini-batch 的均值和方差，$\epsilon$ 用于防止除零错误。</p></li><li><p><strong>仿射变换</strong>：<br>归一化之后，使用可学习的参数 $\gamma$ （缩放）和 $\beta$（平移） 对激活值进行缩放和偏移：</p></li></ul><p>$$<br>y&#x3D;\gamma \hat{x}+\beta<br>$$</p><ul><li><p><strong>训练阶段</strong>：<br>在训练过程中，使用 mini-batch 的统计量进行归一化。同时，利用移动平均对均值 $\mu_B$ 和方差 $\sigma_B^2$ 进行估算，以便在推理时使用。</p></li><li><p><strong>推理阶段</strong>：<br>在推理阶段，使用固定的均值和方差（训练时的全局统计量）进行归一化，确保输出是确定的。</p></li></ul><h2 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h2><ul><li><p><strong>数据集</strong>：在 CIFAR-10、ImageNet 等基准数据集上进行测试。</p></li><li><p><strong>结果</strong>：</p><ul><li><p>BN显著加速了收敛（例如在 ImageNet 上，训练时间减少了多达 14 倍）。</p></li><li><p>与没有BN的模型相比，BN 提高了模型的准确率。</p></li></ul></li><li><p><strong>消融实验</strong>：</p><ul><li><p>显示了 $\gamma$ 和 $\beta$ 的重要性，以及 mini-batch 归一化的有效性。</p></li><li><p>BN 具有一定的正则化效果，减少了对 Dropout 的需求。</p></li></ul></li></ul><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>批量归一化提出了一种简单有效的方法来稳定并加速深度神经网络的训练。它通过减少内部协变量偏移，能够加快收敛速度并提高泛化能力。BN 的普适性和有效性使其成为现代深度学习架构中的标准组件。研究强调了解决网络内部分布变化问题对提升训练效率的重要性。</p><h2 id="8-Notes"><a href="#8-Notes" class="headerlink" title="8. Notes"></a>8. Notes</h2><ol><li>为什么要进行归一化？</li></ol><blockquote><ul><li><p><strong>避免梯度消失或梯度爆炸：</strong></p><ul><li><strong>梯度消失：</strong><br>对于偏大的通道值，激活函数（如 Sigmoid 或 Tanh）的输出可能趋近其饱和区间（例如，Sigmoid 趋近于 0 或 1）。在饱和区域，导数接近于 0，导致梯度几乎消失，权重无法有效更新。</li><li><strong>梯度爆炸：</strong><br>对于偏小的通道值，激活函数的导数可能非常大，导致梯度在反向传播过程中不断累积并放大，最终引起梯度爆炸。</li></ul><p> 这些现象会使优化过程变得极其不稳定，甚至使模型无法收敛。</p></li><li><p><strong>平衡通道值范围：</strong></p><ul><li>如果不同通道的值范围差异显著：<ul><li><strong>梯度更新受大值主导：</strong> 较大的值会主导梯度更新方向，网络可能优先调整这些通道的权重。</li><li><strong>忽略小值信息：</strong> 较小值的通道可能被忽略，导致网络无法充分利用所有特征信息。</li></ul></li></ul><p> 这种不平衡会降低模型的学习效率，延长训练时间，并难以达到最佳性能。</p></li><li><p><strong>简化损失函数的优化过程：</strong></p><ul><li>通道间值差异较大时，损失函数的形状可能会变得复杂（例如，陡峭的谷底或平坦的高原）。</li><li>优化器可能需要更小的学习率逐渐调整权重，从而减慢模型的收敛速度。</li></ul></li></ul></blockquote>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>训练加速</tag>
      
      <tag>算法优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文笔记 - Going Deeper with Convolutions</title>
    <link href="/2024/11/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Going-Deeper-with-Convolutions/"/>
    <url>/2024/11/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Going-Deeper-with-Convolutions/</url>
    
    <content type="html"><![CDATA[<h2 id="1-Information"><a href="#1-Information" class="headerlink" title="1. Information"></a>1. Information</h2><p><strong>Title</strong>: Going Deeper with Convolutions<br><strong>Link</strong>: <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf">Inception V1 Paper</a><br><strong>Source</strong>: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br><strong>Date</strong>: 2015</p><h2 id="2-Summary"><a href="#2-Summary" class="headerlink" title="2. Summary"></a>2. Summary</h2><p>本文提出了一种名为 <strong>Inception</strong> 的深度卷积神经网络架构，在提高模型深度和宽度的同时，保持计算开销较低。基于此架构设计的 <strong>GoogLeNet</strong> 在图像分类和目标检测任务中取得了显著的性能提升。其核心思想是通过多个并行计算路径近似局部稀疏结构，兼顾了计算效率和模型精度。</p><h2 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h2><ul><li><p>深度学习的发展依赖于更强大的硬件、更大的数据集以及更高效的网络架构。然而，在移动设备或嵌入式环境中，功耗和内存限制要求算法需更高效。</p></li><li><p>增大网络规模虽能提升性能，但带来了两个问题：</p><ol><li><p>容易过拟合，需要昂贵的高质量标注数据。</p></li><li><p>参数利用率低，造成计算资源浪费。</p></li></ol></li><li><p>稀疏网络可减少计算量，但现代硬件在稀疏计算上效率不高。</p></li></ul><h2 id="4-Research-Objective"><a href="#4-Research-Objective" class="headerlink" title="4. Research Objective"></a>4. Research Objective</h2><p>设计一种高效的网络架构，在降低计算复杂度和参数量的同时，保留深度模型的表达能力。通过使用密集的并行模块近似稀疏性，解决传统稀疏结构难以高效并行的问题。</p><h2 id="5-Method"><a href="#5-Method" class="headerlink" title="5. Method"></a>5. Method</h2><ul><li><p><strong>核心思想</strong>：</p><ol><li>使用 <strong>1×1、3×3 和 5×5 卷积</strong> 提取多尺度特征，同时结合池化操作以捕获全局信息。</li><li>在大卷积核之前加入 <strong>1×1 卷积</strong>，用于降维和提升非线性表达能力。</li><li>通过模块化设计，平衡计算成本和特征提取能力。</li></ol></li><li><p><strong>网络结构</strong>：</p><ul><li>初版 Inception 模块中并行使用不同卷积核和池化操作，会导致通道数增加过快。</li></ul></li></ul><p align="center">  <img src="1.png" style="zoom:50%;" /></p><ul><li>改进版通过在每条路径前增加 <strong>1×1 卷积降维</strong>，有效控制通道数，降低参数量。</li></ul><p align="center">  <img src="2.png" style="zoom:50%;" /></p><ul><li>GoogLeNet 总体架构：<ul><li>采用多层 Inception 模块堆叠，深度增加但计算效率较高。</li><li>引入辅助分类器（仅训练时使用）缓解梯度消失问题。</li></ul></li></ul><p align="center">  <img src="3.png" style="zoom:50%;" /></p><h2 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h2><h3 id="①-图像分类任务"><a href="#①-图像分类任务" class="headerlink" title="① 图像分类任务"></a>① 图像分类任务</h3><ul><li>数据集：ImageNet</li><li>GoogLeNet 在分类任务中取得了 6.67% 的 top-5 错误率，相比 AlexNet 和 VGG 显著提升。</li></ul><p align="center">  <img src="4.png" style="zoom:50%;" /></p><h3 id="②-目标检测任务"><a href="#②-目标检测任务" class="headerlink" title="② 目标检测任务"></a>② 目标检测任务</h3><ul><li>数据集：PASCAL VOC 和 COCO</li><li>在目标检测任务中，结合 Inception 的 R-CNN 模型在精度和效率上表现出色。</li></ul><p align="center">  <img src="5.png" style="zoom:50%;" /></p><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><ul><li><strong>稀疏性近似</strong>：通过并行使用多尺度卷积和池化操作，Inception 模块模拟局部稀疏结构，既降低了计算复杂度，又避免了稀疏计算的硬件瓶颈。</li><li><strong>模块化设计</strong>：使用 1×1 卷积降维，控制通道数增长，有效减少参数量和内存占用。</li><li><strong>高效性能</strong>：GoogLeNet 在分类和检测任务上均实现了卓越的性能，是一种计算资源友好的深度学习模型。</li></ul><h2 id="8-Notes"><a href="#8-Notes" class="headerlink" title="8. Notes"></a>8. Notes</h2><ol><li><strong>1×1 卷积的作用</strong>：</li></ol><blockquote><ul><li>降维与升维</li><li>降低参数量</li><li>跨通道信息融合</li><li>提高非线性表达能力</li></ul></blockquote><ol start="2"><li><strong>辅助分类器的设计注意事项</strong>：</li></ol><blockquote><ul><li><p>如果设计不当，可能干扰主分类器优化。</p></li><li><p>解决方法包括降低辅助分类器损失权重或简化其结构。</p></li></ul></blockquote>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>算法优化</tag>
      
      <tag>CV</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
